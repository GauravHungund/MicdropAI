# ğŸ—ï¸ EchoDuo Architecture

Detailed architectural documentation for the EchoDuo AI podcast generation system.

## System Overview

EchoDuo is a sophisticated multi-component system that generates natural podcast conversations with intelligently embedded sponsors. The architecture emphasizes autonomy, self-improvement, and contextual awareness.

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Interface Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   CLI Tool  â”‚  â”‚  Flask API  â”‚  â”‚  Web Interface (HTML)   â”‚ â”‚
â”‚  â”‚ (echoduo.py)â”‚  â”‚  (api.py)   â”‚  â”‚  (web_interface.html)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                      â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Core Generation Engine                      â”‚
â”‚                   (podcast_generator.py)                      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Context Gathering       (Lightpanda Scraper)        â”‚ â”‚
â”‚  â”‚  2. Memory Check            (Redis Memory Manager)      â”‚ â”‚
â”‚  â”‚  3. Sponsor Selection       (LLM-based ranking)         â”‚ â”‚
â”‚  â”‚  4. Initial Generation      (AWS Bedrock - Claude)      â”‚ â”‚
â”‚  â”‚  5. Self-Critique           (LLM as critic)             â”‚ â”‚
â”‚  â”‚  6. Improvement Loop        (Iterative refinement)      â”‚ â”‚
â”‚  â”‚  7. Memory Update           (Store patterns)            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                â”‚                  â”‚
           â–¼                â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Lightpanda     â”‚  â”‚    Redis     â”‚  â”‚  Claude API    â”‚
â”‚    Scraper       â”‚  â”‚   Memory     â”‚  â”‚  (Anthropic)   â”‚
â”‚ - Web scraping   â”‚  â”‚ - Sponsors   â”‚  â”‚ - Generation   â”‚
â”‚ - Context fetch  â”‚  â”‚ - Phrases    â”‚  â”‚ - Critique     â”‚
â”‚ - Fallbacks      â”‚  â”‚ - Patterns   â”‚  â”‚ - Improvement  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Podcast Generator (`podcast_generator.py`)

**Purpose:** Core orchestrator for the entire generation pipeline.

**Key Methods:**
- `generate()` - Main entry point, orchestrates entire flow
- `select_sponsor()` - Uses LLM to choose most relevant sponsor
- `generate_initial_conversation()` - Creates first draft
- `critique_and_improve()` - Self-improvement loop
- `extract_key_phrases()` - Memory extraction

**Flow:**
1. Receive topic + optional context
2. Fetch real-world context (if not provided)
3. Load memory (recent sponsors/phrases)
4. Select appropriate sponsor
5. Generate initial conversation
6. Critique and improve
7. Update memory
8. Return final result

### 2. Claude Client (`claude_client.py`)

**Purpose:** Interface with Anthropic's Claude API.

**Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Claude Client                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  generate()                         â”‚
â”‚  â”œâ”€ Standard generation             â”‚
â”‚  â”œâ”€ Temperature control             â”‚
â”‚  â””â”€ Token management                â”‚
â”‚                                     â”‚
â”‚  generate_streaming()               â”‚
â”‚  â”œâ”€ Stream text chunks              â”‚
â”‚  â”œâ”€ Real-time output                â”‚
â”‚  â””â”€ Lower latency                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features:**
- Simple API key authentication
- Error handling with Anthropic SDK
- Support for streaming responses
- Configurable temperature and max tokens

### 3. Memory Manager (`memory_manager.py`)

**Purpose:** Persistent memory using Redis with in-memory fallback.

**Data Structures:**

```redis
recent_sponsors: LIST
â”œâ”€ [0] "Calm"
â”œâ”€ [1] "Nike"
â””â”€ [2] "Notion"

recent_phrases: LIST
â”œâ”€ [0] "I've been thinking about"
â”œâ”€ [1] "That's really interesting"
â””â”€ [2] "Let me tell you"

tone_patterns: LIST
â”œâ”€ [0] "AI-automation-Coder"
â””â”€ [1] "mental-health-Calm"
```

**Operations:**
- `add_sponsor()` - LPUSH with LTRIM to maintain size
- `get_recent_sponsors()` - LRANGE to retrieve
- Automatic fallback to dict if Redis unavailable

### 4. Lightpanda Scraper (`lightpanda_scraper.py`)

**Purpose:** Real-world context gathering from web.

**Strategy:**
```
Topic â†’ Search Strategy â†’ URL Fetch â†’ Content Extract â†’ Clean â†’ Return
```

**Features:**
- Multi-source scraping
- Intelligent fallbacks for common topics
- BeautifulSoup parsing
- Rate limiting and politeness
- Content truncation (1000 chars per source)

**Fallback System:**
```python
{
    "AI taking over jobs": "Recent reports show...",
    "mental health": "WHO reports...",
    "remote work": "Studies show...",
    # ... more fallbacks
}
```

## Prompt Engineering Architecture

### Sponsor Selection Prompt

```
Context: Topic + Available Sponsors + Descriptions
Task: Match topic to sponsor semantically
Output: Single sponsor name
Temperature: 0.3 (deterministic)
Max Tokens: 50
```

### Initial Conversation Generation Prompt

```
System Prompt:
â”œâ”€ Host personalities defined
â”œâ”€ Format rules (Alex:/Maya:)
â”œâ”€ No narration rule
â””â”€ Sponsor integration guidelines

User Prompt:
â”œâ”€ Topic
â”œâ”€ Real-world context
â”œâ”€ Chosen sponsor
â”œâ”€ Recent memory (avoid patterns)
â””â”€ Length guidelines (12-18 exchanges)

Temperature: 0.8 (creative)
Max Tokens: 3000
```

### Critique and Improvement Prompt

```
Role: Harsh critic + improver
Input: Original conversation + evaluation criteria
Process:
â”œâ”€ Mental critique (internal)
â”œâ”€ Identify issues
â””â”€ Generate improved version

Output: Only improved conversation
Temperature: 0.7 (balanced)
Max Tokens: 3500
```

## Self-Improvement Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Self-Improvement Cycle              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                  â”‚
â”‚  1. Generate Alpha Version                      â”‚
â”‚     â”œâ”€ Topic + Context + Sponsor                â”‚
â”‚     â””â”€ Output: initial_conversation             â”‚
â”‚                                                  â”‚
â”‚  2. Analyze                                     â”‚
â”‚     â”œâ”€ Naturalness check                        â”‚
â”‚     â”œâ”€ Sponsor integration quality              â”‚
â”‚     â”œâ”€ Flow and transitions                     â”‚
â”‚     â”œâ”€ Host voice distinctiveness               â”‚
â”‚     â””â”€ Engagement level                         â”‚
â”‚                                                  â”‚
â”‚  3. Generate Beta Version                       â”‚
â”‚     â”œâ”€ Fix identified issues                    â”‚
â”‚     â”œâ”€ Enhance natural flow                     â”‚
â”‚     â””â”€ Output: improved_conversation            â”‚
â”‚                                                  â”‚
â”‚  4. Return Final                                â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Memory System Architecture

### Memory Lifecycle

```
Episode 1:
â”œâ”€ Generate conversation
â”œâ”€ Select sponsor: "Calm"
â”œâ”€ Store in Redis: recent_sponsors[0] = "Calm"
â””â”€ Extract phrases: ["I've been thinking", "That's interesting"]

Episode 2:
â”œâ”€ Load memory: recent_sponsors = ["Calm"]
â”œâ”€ Exclude "Calm" from selection
â”œâ”€ Select different sponsor: "Nike"
â”œâ”€ Avoid phrases: ["I've been thinking", "That's interesting"]
â””â”€ Generate with new patterns

Episode 6:
â”œâ”€ Sponsor list full (5 entries)
â”œâ”€ LTRIM removes oldest
â””â”€ "Calm" now available again
```

### Memory Priority

1. **Sponsors**: Last 5 used â†’ Prevent immediate repetition
2. **Phrases**: Last 20 used â†’ Avoid formulaic language
3. **Tone Patterns**: Last 10 used â†’ Vary conversation style

## API Architecture

### REST Endpoints

```
POST /generate
â”œâ”€ Body: { topic, context?, sponsor? }
â”œâ”€ Process: Full generation pipeline
â””â”€ Response: { conversation, sponsor, topic, context }

GET /memory
â”œâ”€ Process: Retrieve current state
â””â”€ Response: { recent_sponsors[], recent_phrases[], tone_patterns[] }

POST /memory/clear
â”œâ”€ Process: Clear all Redis keys
â””â”€ Response: { success: true }

GET /sponsors
â”œâ”€ Process: Return available sponsors
â””â”€ Response: { sponsors: [...] }

GET /health
â””â”€ Response: { status: "healthy" }
```

## Data Flow Diagram

```
User Input (Topic)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lightpanda Scraper â”‚ â”€â”€â†’ Real-world Context
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Manager    â”‚ â”€â”€â†’ Recent Sponsors/Phrases
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sponsor Selector   â”‚ â”€â”€â†’ Chosen Sponsor
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Initial Generator  â”‚ â”€â”€â†’ Alpha Conversation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Critic System    â”‚ â”€â”€â†’ Analysis
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Improver System   â”‚ â”€â”€â†’ Beta Conversation
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Memory Update     â”‚ â”€â”€â†’ Store Patterns
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Final Output (Conversation)
```

## Error Handling Strategy

### Graceful Degradation

```
AWS Bedrock Failure
â”œâ”€ Retry with exponential backoff
â”œâ”€ Log error details
â””â”€ Raise exception (no silent failure)

Redis Connection Failure
â”œâ”€ Automatic fallback to in-memory dict
â”œâ”€ Warning message to user
â””â”€ Continue operation normally

Web Scraping Failure
â”œâ”€ Try multiple sources
â”œâ”€ Use fallback context library
â””â”€ Synthetic context generation

Invalid Sponsor Selection
â”œâ”€ Validate against AVAILABLE_SPONSORS
â”œâ”€ Fallback to first available
â””â”€ Log warning
```

## Performance Characteristics

### Latency

- Lightpanda scraping: 3-5 seconds
- Memory operations: <10ms (Redis) or <1ms (in-memory)
- Sponsor selection: 1-2 seconds (API call)
- Initial generation: 15-25 seconds (API call)
- Critique + improvement: 20-30 seconds (API call)
- **Total: ~45-65 seconds per episode**

### Cost (per episode via Anthropic API)

- Claude 3.5 Sonnet input: ~1,500 tokens @ $3/MTok = $0.0045
- Claude 3.5 Sonnet output: ~2,000 tokens @ $15/MTok = $0.030
- **Total: ~$0.035-0.10 per episode**

### Scalability

- **Horizontal:** Multiple API instances behind load balancer
- **Vertical:** Increase Anthropic API rate limits (contact support)
- **Caching:** Redis can handle 100K+ episodes metadata
- **Async:** Could parallelize scraping + memory ops

## Security Considerations

1. **API Keys**: Stored in `.env`, never committed
2. **Redis**: Optional password authentication
3. **API**: CORS enabled, add rate limiting for production
4. **Input Validation**: Sanitize topics to prevent injection
5. **Content Safety**: Anthropic API has built-in safety filters

## Future Architecture Extensions

### Potential Enhancements

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Audio Generation Layer          â”‚
â”‚  (AWS Polly / ElevenLabs)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Multi-Episode Story Arc Engine    â”‚
â”‚  (Track themes across episodes)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    A/B Testing & Analytics          â”‚
â”‚  (Track engagement metrics)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Automated Publishing Pipeline     â”‚
â”‚  (RSS, Spotify, Apple Podcasts)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration Management

```python
# config.py structure
â”œâ”€ Anthropic API Configuration (api_key)
â”œâ”€ Redis Configuration (host, port, auth)
â”œâ”€ Model Configuration (model_name, max_tokens, temperature)
â”œâ”€ Podcast Configuration (sponsors list)
â””â”€ Memory Configuration (history sizes)
```

All config exposed via environment variables for 12-factor app compliance.

---

**Last Updated:** November 2025  
**Version:** 1.0.0  
**Maintainer:** EchoDuo Team

